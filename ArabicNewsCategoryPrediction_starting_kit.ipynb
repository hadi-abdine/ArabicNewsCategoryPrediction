{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "<table style=\"width:100%; background-color:transparent;\">\n",
    "  <tr style=\"background-color:transparent;\">\n",
    "    <td style=\"background-color:transparent;\">\n",
    "<img border=\"0\" src=\"https://www.polytechnique.edu/sites/all/institutionnel/institutpolytechniqueparis_logohorizontal.png\" width=\"90%\"> </td>\n",
    "     <td style=\"background-color:transparent;\">\n",
    "<img border=\"0\" src=\"\" width=\"60%\"> </td>\n",
    "  </tr>\n",
    "</table> \n",
    "</div>\n",
    "<center><h1>Arabic News Category Prediction Challenge (ANCP)</h1></center>\n",
    "<br/>\n",
    "<center>Ahmad CHAMMA, Hadi ABDINE, Youssef FARHAT</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import datetime\n",
    "import dateutil.parser as dparser\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import unicodedata as ud\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import get_train_data\n",
    "X_df, y_array = get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1313318</td>\n",
       "      <td>تكريم الشاعر موسى زغي ورئيس الجمهورية قلده وسا...</td>\n",
       "      <td>الخميس 12 نيسان 2018 - 15:37</td>\n",
       "      <td>\\n\\r\\n\\tكرمت جامعة الروح القدس - الكسليك وجامع...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/12-04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1413607</td>\n",
       "      <td>نائب معارض لمادورو: حزب الله يستثمر منجمين للذ...</td>\n",
       "      <td>الاثنين 14 كانون الثاني 2019 - 15:58</td>\n",
       "      <td>\\n\\n\\tكشف نائب معارض للرئيس الفنزويلي نيكولاس ...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/14-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1363260</td>\n",
       "      <td>هكذا استغل داعش الأطفال في هجمات الشيشان</td>\n",
       "      <td>الخميس 23 آب 2018 - 07:29</td>\n",
       "      <td>\\n\\n\\tنشر تنظيم داعش مقطع فيديو، الأربعاء، يظه...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/23-08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>971779</td>\n",
       "      <td>سلام ترأس اجتماعا لخلية الازمة الوزارية</td>\n",
       "      <td>الاثنين 07 كانون الأول 2015 - 18:48</td>\n",
       "      <td>\\n\\r\\n\\tترأس رئيس مجلس الوزراء تمام سلام اجتما...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/07-12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>960499</td>\n",
       "      <td>كنعان: وصلنا الى اتفاق حول اقتراح قانون استعاد...</td>\n",
       "      <td>الأربعاء 11 تشرين الثاني 2015 - 15:01</td>\n",
       "      <td>\\n\\r\\n\\tعقد نواب من \"التيار الوطني الحر\" والمس...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/11-11...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              Title  \\\n",
       "0  1313318  تكريم الشاعر موسى زغي ورئيس الجمهورية قلده وسا...   \n",
       "1  1413607  نائب معارض لمادورو: حزب الله يستثمر منجمين للذ...   \n",
       "2  1363260           هكذا استغل داعش الأطفال في هجمات الشيشان   \n",
       "3   971779            سلام ترأس اجتماعا لخلية الازمة الوزارية   \n",
       "4   960499  كنعان: وصلنا الى اتفاق حول اقتراح قانون استعاد...   \n",
       "\n",
       "                                    Date  \\\n",
       "0           الخميس 12 نيسان 2018 - 15:37   \n",
       "1   الاثنين 14 كانون الثاني 2019 - 15:58   \n",
       "2              الخميس 23 آب 2018 - 07:29   \n",
       "3    الاثنين 07 كانون الأول 2015 - 18:48   \n",
       "4  الأربعاء 11 تشرين الثاني 2015 - 15:01   \n",
       "\n",
       "                                                Desc  \\\n",
       "0  \\n\\r\\n\\tكرمت جامعة الروح القدس - الكسليك وجامع...   \n",
       "1  \\n\\n\\tكشف نائب معارض للرئيس الفنزويلي نيكولاس ...   \n",
       "2  \\n\\n\\tنشر تنظيم داعش مقطع فيديو، الأربعاء، يظه...   \n",
       "3  \\n\\r\\n\\tترأس رئيس مجلس الوزراء تمام سلام اجتما...   \n",
       "4  \\n\\r\\n\\tعقد نواب من \"التيار الوطني الحر\" والمس...   \n",
       "\n",
       "                                               Image  \n",
       "0  http://www.lebanonfiles.com/files/images/12-04...  \n",
       "1  http://www.lebanonfiles.com/files/images/14-01...  \n",
       "2  http://www.lebanonfiles.com/files/images/23-08...  \n",
       "3  http://www.lebanonfiles.com/files/images/07-12...  \n",
       "4  http://www.lebanonfiles.com/files/images/11-11...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = int(len(X_df) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = X_df[:length]\n",
    "y_array = y_array[:length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the arabic date to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_date(x):\n",
    "    dicta =  {\"كانون الثاني\": \"january\" ,\"شباط\": \"february\", \"أيار\": \"may\",  \"نيسان\": \"April\",\n",
    "         \"آذار\": \"march\", \"حزيران\": \"june\", \"تموز\": \"july\", \"آب\": \"august\", \"أيلول\": \"september\",\n",
    "         \"تشرين الأول\": \"october\", \"تشرين الثاني\": \"november\", \"كانون الأول\": \"december\",\n",
    "         \"الاثنين\": \"monday\", \"الثلاثاء\": \"tuesday\", \"الأربعاء\": \"wednesday\", \"الخميس\": \"thursday\", \"الجمعة\": \"friday\",\n",
    "         \"السبت\": \"saturday\", \"الأحد\": \"sunday\", \"السبت\": \"saturday\"}\n",
    "    x_new = x\n",
    "    for arabic, english in dicta.items():\n",
    "        x_new = x_new.replace(arabic, english)\n",
    "    x_new = dparser.parse(x_new, fuzzy=True)\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1313318</td>\n",
       "      <td>تكريم الشاعر موسى زغي ورئيس الجمهورية قلده وسا...</td>\n",
       "      <td>2018-04-12 15:37:00</td>\n",
       "      <td>\\n\\r\\n\\tكرمت جامعة الروح القدس - الكسليك وجامع...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/12-04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1413607</td>\n",
       "      <td>نائب معارض لمادورو: حزب الله يستثمر منجمين للذ...</td>\n",
       "      <td>2019-01-14 15:58:00</td>\n",
       "      <td>\\n\\n\\tكشف نائب معارض للرئيس الفنزويلي نيكولاس ...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/14-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1363260</td>\n",
       "      <td>هكذا استغل داعش الأطفال في هجمات الشيشان</td>\n",
       "      <td>2018-08-23 07:29:00</td>\n",
       "      <td>\\n\\n\\tنشر تنظيم داعش مقطع فيديو، الأربعاء، يظه...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/23-08...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              Title  \\\n",
       "0  1313318  تكريم الشاعر موسى زغي ورئيس الجمهورية قلده وسا...   \n",
       "1  1413607  نائب معارض لمادورو: حزب الله يستثمر منجمين للذ...   \n",
       "2  1363260           هكذا استغل داعش الأطفال في هجمات الشيشان   \n",
       "\n",
       "                 Date                                               Desc  \\\n",
       "0 2018-04-12 15:37:00  \\n\\r\\n\\tكرمت جامعة الروح القدس - الكسليك وجامع...   \n",
       "1 2019-01-14 15:58:00  \\n\\n\\tكشف نائب معارض للرئيس الفنزويلي نيكولاس ...   \n",
       "2 2018-08-23 07:29:00  \\n\\n\\tنشر تنظيم داعش مقطع فيديو، الأربعاء، يظه...   \n",
       "\n",
       "                                               Image  \n",
       "0  http://www.lebanonfiles.com/files/images/12-04...  \n",
       "1  http://www.lebanonfiles.com/files/images/14-01...  \n",
       "2  http://www.lebanonfiles.com/files/images/23-08...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df['Date'] = X_df.Date.apply(convert_to_date)\n",
    "X_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11640, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id       0.000000\n",
       "Title    0.000000\n",
       "Date     0.000000\n",
       "Desc     0.000515\n",
       "Image    0.037113\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proportion of NaN values\n",
    "X_df.isna().sum() / X_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id       11640\n",
       "Title    11616\n",
       "Date     11582\n",
       "Desc     11634\n",
       "Image    11182\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique values\n",
    "X_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                int64\n",
       "Title            object\n",
       "Date     datetime64[ns]\n",
       "Desc             object\n",
       "Image            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.164000e+04</td>\n",
       "      <td>11640</td>\n",
       "      <td>11640</td>\n",
       "      <td>11634</td>\n",
       "      <td>11208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11616</td>\n",
       "      <td>11582</td>\n",
       "      <td>11634</td>\n",
       "      <td>11182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>الدفاع المدني: مهمات إنقاذ وإسعاف وإخماد حرائق...</td>\n",
       "      <td>2015-08-27 16:50:00</td>\n",
       "      <td>\\n\\n\\tوجه النائب سرج طور سركيسيان، في بيان \"ان...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/10-02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-06-21 12:24:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-15 08:25:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.282918e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.243605e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000080e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.982312e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.371369e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.459972e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.560309e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id                                              Title  \\\n",
       "count   1.164000e+04                                              11640   \n",
       "unique           NaN                                              11616   \n",
       "top              NaN  الدفاع المدني: مهمات إنقاذ وإسعاف وإخماد حرائق...   \n",
       "freq             NaN                                                 12   \n",
       "first            NaN                                                NaN   \n",
       "last             NaN                                                NaN   \n",
       "mean    1.282918e+06                                                NaN   \n",
       "std     2.243605e+05                                                NaN   \n",
       "min     9.000080e+05                                                NaN   \n",
       "25%     9.982312e+05                                                NaN   \n",
       "50%     1.371369e+06                                                NaN   \n",
       "75%     1.459972e+06                                                NaN   \n",
       "max     1.560309e+06                                                NaN   \n",
       "\n",
       "                       Date  \\\n",
       "count                 11640   \n",
       "unique                11582   \n",
       "top     2015-08-27 16:50:00   \n",
       "freq                      2   \n",
       "first   2015-06-21 12:24:00   \n",
       "last    2020-01-15 08:25:00   \n",
       "mean                    NaN   \n",
       "std                     NaN   \n",
       "min                     NaN   \n",
       "25%                     NaN   \n",
       "50%                     NaN   \n",
       "75%                     NaN   \n",
       "max                     NaN   \n",
       "\n",
       "                                                     Desc  \\\n",
       "count                                               11634   \n",
       "unique                                              11634   \n",
       "top     \\n\\n\\tوجه النائب سرج طور سركيسيان، في بيان \"ان...   \n",
       "freq                                                    1   \n",
       "first                                                 NaN   \n",
       "last                                                  NaN   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                                    Image  \n",
       "count                                               11208  \n",
       "unique                                              11182  \n",
       "top     http://www.lebanonfiles.com/files/images/10-02...  \n",
       "freq                                                    3  \n",
       "first                                                 NaN  \n",
       "last                                                  NaN  \n",
       "mean                                                  NaN  \n",
       "std                                                   NaN  \n",
       "min                                                   NaN  \n",
       "25%                                                   NaN  \n",
       "50%                                                   NaN  \n",
       "75%                                                   NaN  \n",
       "max                                                   NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['أخبار محليّة', 'أخبار فنية', 'أخبار اقتصادية ومالية', 'أخبار رياضية', 'أخبار إقليمية ودولية']\n",
    "class2index = dict(zip(categories, range(len(categories))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_array = np.array([class2index[cat] for cat in y_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7147.,    0.,  842.,    0.,    0.,  946.,    0.,  745.,    0.,\n",
       "        1960.]),\n",
       " array([0. , 0.4, 0.8, 1.2, 1.6, 2. , 2.4, 2.8, 3.2, 3.6, 4. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see the data is unbalanced so as scorer we use the F1 Score as scorer dor our challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive fill for the \"Desc\" Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_df['Desc'] = X_df['Desc'].astype('str')\n",
    "X_df.loc[X_df['Desc']=='', 'Desc'] = X_df['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1313318</td>\n",
       "      <td>تكريم الشاعر موسى زغي ورئيس الجمهورية قلده وسا...</td>\n",
       "      <td>2018-04-12 15:37:00</td>\n",
       "      <td>\\n\\r\\n\\tكرمت جامعة الروح القدس - الكسليك وجامع...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/12-04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1413607</td>\n",
       "      <td>نائب معارض لمادورو: حزب الله يستثمر منجمين للذ...</td>\n",
       "      <td>2019-01-14 15:58:00</td>\n",
       "      <td>\\n\\n\\tكشف نائب معارض للرئيس الفنزويلي نيكولاس ...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/14-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1363260</td>\n",
       "      <td>هكذا استغل داعش الأطفال في هجمات الشيشان</td>\n",
       "      <td>2018-08-23 07:29:00</td>\n",
       "      <td>\\n\\n\\tنشر تنظيم داعش مقطع فيديو، الأربعاء، يظه...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/23-08...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              Title  \\\n",
       "0  1313318  تكريم الشاعر موسى زغي ورئيس الجمهورية قلده وسا...   \n",
       "1  1413607  نائب معارض لمادورو: حزب الله يستثمر منجمين للذ...   \n",
       "2  1363260           هكذا استغل داعش الأطفال في هجمات الشيشان   \n",
       "\n",
       "                 Date                                               Desc  \\\n",
       "0 2018-04-12 15:37:00  \\n\\r\\n\\tكرمت جامعة الروح القدس - الكسليك وجامع...   \n",
       "1 2019-01-14 15:58:00  \\n\\n\\tكشف نائب معارض للرئيس الفنزويلي نيكولاس ...   \n",
       "2 2018-08-23 07:29:00  \\n\\n\\tنشر تنظيم داعش مقطع فيديو، الأربعاء، يظه...   \n",
       "\n",
       "                                               Image  \n",
       "0  http://www.lebanonfiles.com/files/images/12-04...  \n",
       "1  http://www.lebanonfiles.com/files/images/14-01...  \n",
       "2  http://www.lebanonfiles.com/files/images/23-08...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the \"Desc\" and \"Title\" column (remove \\t, weird symbols and stop words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stps_arabic = set(stopwords.words('arabic'))\n",
    "arabic_diacritics = re.compile(\"\"\"\n",
    "                             ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "\n",
    "def clean_txt(sent):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"    \n",
    "    text = sent.strip()\n",
    "    text = re.sub('[\\n\\r\\t\\xa0]', ' ', text)\n",
    "    text = re.sub(arabic_diacritics, '', text)\n",
    "    text = ''.join(c for c in text if not ud.category(c).startswith('P') and not c.isdigit())\n",
    "    res = re.sub(' +', ' ', text)\n",
    "    return [w for w in text.split() if w not in stps_arabic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df['Title'] = X_df['Title'].apply(clean_txt)\n",
    "X_df['Desc'] = X_df['Desc'].apply(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1313318</td>\n",
       "      <td>[تكريم, الشاعر, موسى, زغي, ورئيس, الجمهورية, ق...</td>\n",
       "      <td>2018-04-12 15:37:00</td>\n",
       "      <td>[كرمت, جامعة, الروح, القدس, الكسليك, وجامعة, آ...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/12-04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1413607</td>\n",
       "      <td>[نائب, معارض, لمادورو, حزب, الله, يستثمر, منجم...</td>\n",
       "      <td>2019-01-14 15:58:00</td>\n",
       "      <td>[كشف, نائب, معارض, للرئيس, الفنزويلي, نيكولاس,...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/14-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1363260</td>\n",
       "      <td>[استغل, داعش, الأطفال, هجمات, الشيشان]</td>\n",
       "      <td>2018-08-23 07:29:00</td>\n",
       "      <td>[نشر, تنظيم, داعش, مقطع, فيديو, الأربعاء, يظهر...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/23-08...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              Title  \\\n",
       "0  1313318  [تكريم, الشاعر, موسى, زغي, ورئيس, الجمهورية, ق...   \n",
       "1  1413607  [نائب, معارض, لمادورو, حزب, الله, يستثمر, منجم...   \n",
       "2  1363260             [استغل, داعش, الأطفال, هجمات, الشيشان]   \n",
       "\n",
       "                 Date                                               Desc  \\\n",
       "0 2018-04-12 15:37:00  [كرمت, جامعة, الروح, القدس, الكسليك, وجامعة, آ...   \n",
       "1 2019-01-14 15:58:00  [كشف, نائب, معارض, للرئيس, الفنزويلي, نيكولاس,...   \n",
       "2 2018-08-23 07:29:00  [نشر, تنظيم, داعش, مقطع, فيديو, الأربعاء, يظهر...   \n",
       "\n",
       "                                               Image  \n",
       "0  http://www.lebanonfiles.com/files/images/12-04...  \n",
       "1  http://www.lebanonfiles.com/files/images/14-01...  \n",
       "2  http://www.lebanonfiles.com/files/images/23-08...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SpatialDropout1D, LSTM, Dense\n",
    "import keras.backend as K\n",
    "\n",
    "# The maximum number of words to be used. (Most frequent)\n",
    "vocab_size = 20000\n",
    "\n",
    "# The padding and truncating types used.\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "\n",
    "# The OOV token (Out Of Vocabulary) will be included within the dictionary\n",
    "oov_tok = '<OOV>'\n",
    "\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 200\n",
    "\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X_df['Desc'].values)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(X_df['Desc'])\n",
    "X = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   35,     7,   157,   583,   135,     6,     3, 11470,  2164,\n",
       "        1909,  1750,   753,  3424, 12633,    68,   137, 17501,  1750,\n",
       "        1170,  5496,  5497,  1812,  3132,  4366,  3133,   135,    24,\n",
       "         224,   526,  2599, 11151,   448,  5099,  1750,   753,  8991,\n",
       "         166,   292,     9,    65,     1,     7,   135,  5099,  1750,\n",
       "         753,    98,    50,    89,   630,  2279,  4040,     1,  5173,\n",
       "          29,  1750,   753,   946,     1,   166,     1,   161, 15261,\n",
       "        3468,   154,   723,     1,    95,    29,   704,   797,  1647,\n",
       "         166,     1,     1,     1,  3990,   268,  4366,  2722,     1,\n",
       "         174,     1,   294,     1,   371,  5252,  1677,  1750,   753,\n",
       "       17501,  6131,  7574,  6132,   135,     1,  3215,  7891,  6347,\n",
       "          61,   132,   102,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "قال الرئيس الأميركي دونالد ترامب اليوم ان إدارته تجري محادثات كوريا الجنوبية تزيد تمويلها بشكل كبير لحمايتها كوريا الشمالية تصاعد التوترات شبه الجزيرة الكورية وكتب ترامب عبر تويتر مدى العقود العديدة الماضية دفعت كوريا الجنوبية القليل جدا المال العام الماضي <OOV> الرئيس ترامب دفعت كوريا الجنوبية مليون دولار وأضاف بدأت المحادثات لزيادة <OOV> للولايات المتحدة كوريا الجنوبية بلد <OOV> جدا <OOV> الآن بالتزام المساهمة الدفاع العسكري <OOV> الولايات المتحدة العلاقة البلدين جيدة جدا <OOV> <OOV> <OOV> أمني الحرب الكورية انتهت <OOV> وليس <OOV> سلام <OOV> ألف جندي أميركي كوريا الجنوبية لحمايتها تهديدات بيونغ يانغ ترامب <OOV> مرارا تكاليف إبقاء القوات الأميركية البلد <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "---\n",
      "قال الرئيس الأميركي دونالد ترامب اليوم ان إدارته تجري محادثات كوريا الجنوبية تزيد تمويلها بشكل كبير لحمايتها كوريا الشمالية تصاعد التوترات شبه الجزيرة الكورية وكتب ترامب عبر تويتر مدى العقود العديدة الماضية دفعت كوريا الجنوبية القليل جدا المال العام الماضي وبطلب الرئيس ترامب دفعت كوريا الجنوبية مليون دولار وأضاف بدأت المحادثات لزيادة الدفعات للولايات المتحدة كوريا الجنوبية بلد ثري جدا ويشعر الآن بالتزام المساهمة الدفاع العسكري توفره الولايات المتحدة العلاقة البلدين جيدة جدا والبلدان يرتبطان بتحالف أمني الحرب الكورية انتهت بهدنة وليس بمعاهدة سلام وينتشر ألف جندي أميركي كوريا الجنوبية لحمايتها تهديدات بيونغ يانغ ترامب اشتكى مرارا تكاليف إبقاء القوات الأميركية البلد\n"
     ]
    }
   ],
   "source": [
    "id_to_word = {value:key for key,value in word_index.items()}\n",
    "id_to_word[0] = '<PAD>'\n",
    "print(' '.join(id_to_word[id] for id in X[10]))\n",
    "print('---')\n",
    "print(' '.join(X_df.loc[10]['Desc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Y_train to one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(y_array.reshape(-1, 1))\n",
    "Y_train = enc.transform(y_array.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the f1_score function (not integrated in Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1(y_true, y_pred):\n",
    "    \n",
    "    y_true=K.cast(y_true, dtype='int32')\n",
    "    y_pred=K.cast(y_pred, dtype='int32')\n",
    "    \n",
    "    prec_num = 0\n",
    "    prec_den = 0\n",
    "    recall_num = 0\n",
    "    recall_den = 0\n",
    "\n",
    "    for i in range(5):\n",
    "        prec_num += K.sum(K.cast((y_true == y_pred) & (y_true == i), \"int32\"))\n",
    "        prec_den += prec_num + K.sum(K.cast((y_true != y_pred) & (y_pred == i), \"int32\"))\n",
    "        recall_num += prec_num\n",
    "        recall_den += prec_num + K.sum(K.cast((y_true != y_pred) & (y_true == i), \"int32\"))\n",
    "    \n",
    "    prec_num = K.cast(prec_num, 'float')\n",
    "    prec_den = K.cast(prec_den, 'float')\n",
    "    recall_num = K.cast(recall_num, 'float')\n",
    "    recall_den = K.cast(recall_den, 'float')\n",
    "    \n",
    "    precision = prec_num / prec_den\n",
    "    recall = recall_num / recall_den\n",
    "    f1_val = 2*(precision * recall)/(precision + recall)\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1(y_true, y_pred):\n",
    "    \n",
    "    y_true=K.cast(y_true, dtype='int32')\n",
    "    y_pred=K.cast(y_pred, dtype='int32')\n",
    "\n",
    "    return K.eval(f1_score(y_true, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got <class 'tensorflow.python.framework.ops.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    740\u001b[0m                     \u001b[0;34m\"Please call `x.shape` rather than `len(x)` for \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                     \"shape information.\".format(self.name))\n\u001b[0m\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: len is not well defined for symbolic Tensors. (metrics/get_f1/Cast:0) Please call `x.shape` rather than `len(x)` for shape information.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-0fbd12593623>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_f1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mskip_target_masks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_functions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             masks=masks)\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;31m# Compute total loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_handle_metrics\u001b[0;34m(self, outputs, targets, skip_target_masks, sample_weights, masks)\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m                 self._handle_per_output_metrics(\n\u001b[0;32m--> 871\u001b[0;31m                     self._per_output_metrics[i], target, output, output_mask)\n\u001b[0m\u001b[1;32m    872\u001b[0m                 self._handle_per_output_metrics(\n\u001b[1;32m    873\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_per_output_weighted_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_handle_per_output_metrics\u001b[0;34m(self, metrics_dict, y_true, y_pred, mask, weights)\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                 training_utils.call_metric_function(\n\u001b[0;32m--> 842\u001b[0;31m                     metric_fn, y_true, y_pred, weights=weights, mask=mask)\n\u001b[0m\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m     def _handle_metrics(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcall_metric_function\u001b[0;34m(metric_fn, y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m         \u001b[0mupdate_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For TF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m             \u001b[0mmetric_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/utils/metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;34m\"\"\"Decorated function with `add_update()`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mmetric_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdate_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/metrics.py\u001b[0m in \u001b[0;36mupdate_state\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze_or_expand_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         return super(MeanMetricWrapper, self).update_state(\n\u001b[1;32m    320\u001b[0m             matches, sample_weight=sample_weight)\n",
      "\u001b[0;32m<ipython-input-48-6c35a0e8d3cd>\u001b[0m in \u001b[0;36mget_f1\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                        zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1224\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1227\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1484\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                          str(average_options))\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \"\"\"\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \"\"\"\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected sequence or array-like, got <class 'tensorflow.python.framework.ops.Tensor'>"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy', get_f1])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 200, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 2,080,905\n",
      "Trainable params: 2,080,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmad/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9894 samples, validate on 1746 samples\n",
      "Epoch 1/10\n",
      "9894/9894 [==============================] - 94s 10ms/step - loss: 1.2039 - accuracy: 0.6084 - get_f1: 0.2956 - val_loss: 1.1657 - val_accuracy: 0.6111 - val_get_f1: 0.2949\n",
      "Epoch 2/10\n",
      "9894/9894 [==============================] - 93s 9ms/step - loss: 1.1022 - accuracy: 0.6279 - get_f1: 0.2956 - val_loss: 0.9266 - val_accuracy: 0.6793 - val_get_f1: 0.2949\n",
      "Epoch 3/10\n",
      "9894/9894 [==============================] - 93s 9ms/step - loss: 0.9164 - accuracy: 0.6461 - get_f1: 0.2956 - val_loss: 0.9211 - val_accuracy: 0.6134 - val_get_f1: 0.2949\n",
      "Epoch 4/10\n",
      "4800/9894 [=============>................] - ETA: 46s - loss: 0.8558 - accuracy: 0.6775 - get_f1: 0.2962"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-d8f0b3774093>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y_array, epochs=epochs, batch_size=batch_size,validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import get_test_data\n",
    "X_test, y_test = get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import get_train_data\n",
    "X_df, y_array = get_train_data()\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='median'))])\n",
    "\n",
    "def convert_to_date(x):\n",
    "    dicta =  {\"كانون الثاني\": \"january\" ,\"شباط\": \"february\", \"أيار\": \"may\",  \"نيسان\": \"April\",\n",
    "        \"آذار\": \"march\", \"حزيران\": \"june\", \"تموز\": \"july\", \"آب\": \"august\", \"أيلول\": \"september\",\n",
    "        \"تشرين الأول\": \"october\", \"تشرين الثاني\": \"november\", \"كانون الأول\": \"december\",\n",
    "        \"الاثنين\": \"monday\", \"الثلاثاء\": \"tuesday\", \"الأربعاء\": \"wednesday\", \"الخميس\": \"thursday\", \"الجمعة\": \"friday\",\n",
    "        \"السبت\": \"saturday\", \"الأحد\": \"sunday\", \"السبت\": \"saturday\"}\n",
    "    x_new = x\n",
    "    for arabic, english in dicta.items():\n",
    "        x_new = x_new.replace(arabic, english)\n",
    "    x_new = dparser.parse(x_new, fuzzy=True)\n",
    "    return x_new\n",
    "def process_date(X):\n",
    "    date = X.Date.apply(convert_to_date)\n",
    "    return np.c_[date.dt.year, date.dt.month, date.dt.day]\n",
    "date_transformer = FunctionTransformer(process_date, validate=False)\n",
    "\n",
    "\n",
    "def clean_txt(sent):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        return: modified initial string\n",
    "    \"\"\"    \n",
    "    stps_arabic = set(stopwords.words('arabic'))\n",
    "    arabic_diacritics = re.compile(\"\"\"\n",
    "                                ّ    | # Tashdid\n",
    "                                َ    | # Fatha\n",
    "                                ً    | # Tanwin Fath\n",
    "                                ُ    | # Damma\n",
    "                                ٌ    | # Tanwin Damm\n",
    "                                ِ    | # Kasra\n",
    "                                ٍ    | # Tanwin Kasr\n",
    "                                ْ    | # Sukun\n",
    "                                ـ     # Tatwil/Kashida\n",
    "                            \"\"\", re.VERBOSE)\n",
    "    sent = str(sent)\n",
    "    text = sent.strip()\n",
    "    text = re.sub('[\\n\\r\\t\\xa0]', ' ', text)\n",
    "    text = re.sub(arabic_diacritics, '', text)\n",
    "    text = ''.join(c for c in text if not ud.category(c).startswith('P') and not c.isdigit())\n",
    "    res = re.sub(' +', ' ', text)\n",
    "    return [w for w in text.split() if w not in stps_arabic]\n",
    "\n",
    "def process_text(X):\n",
    "    X.loc[X['Desc']=='', 'Desc'] = X['Title']\n",
    "    X['Title'] = X['Title'].apply(clean_txt)\n",
    "    X['Desc'] = X['Desc'].apply(clean_txt)\n",
    "    return np.c_[ X['Title'], X['Desc']]\n",
    "\n",
    "\n",
    "num_col = ['Id']\n",
    "date_col = ['Date']\n",
    "drop_cols = ['Image', 'Title', 'Desc']\n",
    "\n",
    "non_text_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('date', make_pipeline(date_transformer), date_col),\n",
    "        ('num', numeric_transformer, num_col),\n",
    "        ('drop cols', 'drop', drop_cols),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array = non_text_preprocessor.fit_transform(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.018000e+03, 4.000000e+00, 1.200000e+01, 1.313318e+06],\n",
       "       [2.019000e+03, 1.000000e+00, 1.400000e+01, 1.413607e+06],\n",
       "       [2.018000e+03, 8.000000e+00, 2.300000e+01, 1.363260e+06],\n",
       "       ...,\n",
       "       [2.019000e+03, 2.000000e+00, 2.000000e+00, 1.422303e+06],\n",
       "       [2.019000e+03, 7.000000e+00, 8.000000e+00, 1.481177e+06],\n",
       "       [2.019000e+03, 1.000000e+00, 7.000000e+00, 1.410380e+06]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_text(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
