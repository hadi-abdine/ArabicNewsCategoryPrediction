{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "<table style=\"width:100%; background-color:transparent;\">\n",
    "  <tr style=\"background-color:transparent;\">\n",
    "    <td style=\"background-color:transparent;\">\n",
    "<img border=\"0\" src=\"https://www.polytechnique.edu/sites/all/institutionnel/institutpolytechniqueparis_logohorizontal.png\" width=\"90%\"> </td>\n",
    "     <td style=\"background-color:transparent;\">\n",
    "<img border=\"0\" src=\"\" width=\"60%\"> </td>\n",
    "  </tr>\n",
    "</table> \n",
    "</div>\n",
    "<center><h1>Arabic News Category Prediction Challenge (ANCP)</h1></center>\n",
    "<br/>\n",
    "<center>Ahmad CHAMMA, Hadi ABDINE, Youssef FARHAT</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "0. [Introduction](#Introduction)\n",
    "1. [Business Model](#Business-Model)\n",
    "2. [KPI and Metric](#KPI-and-Metric)\n",
    "3. [Data](#Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "**Why is Natural Language Processing important?**\n",
    "\n",
    "*A computer could be considered intelligent if it could carry on a conversation with a human being without the human realizing they were talking to a machine.<br>-Alan Turing*\n",
    "\n",
    "By \"natural language\" we mean a language that is used for communication by humans. By combining the power of artificial intelligence, computational linguistics and computer science, Natural Language Processing (NLP) helps machines to understand the natural language and communicate with humans in their own language.\n",
    "\n",
    "<img src=\"files/NLP.png\" width=\"400\">\n",
    "\n",
    "With the ongoing growth of the World Wide Web and social media, there is a drastic increase in online data. As the amount of data increases the mechanisms to process these unstructured data and to extract meaningful information from it becomes more challenging, simply because computers traditionally work with precise, unambiguous and highly structured languages such as programming languages, however, the natural language is often ambiguous and the linguistic structure can depend on many complex variables, including slang, regional dialects and social context. And that is why the development of advanced NLP techniques has been a major topic of research in the last decade. \n",
    "\n",
    "With NLP, ambiguity in language can be resolved and it adds useful numeric structure to the previously unstructed data.From then, sky is the limit on what can be done and the applications that can be developed. For example, NLP makes it possible for computers to read text, translate it, hear speech, interpret it, measure sentiment and determine which parts are important, and that is just tip of the iceberg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Model\n",
    "\n",
    "In this project we are going to be looking into Arabic Natural Language Processing (ANLP). Arabic is the fifth most talked language in the world and is considered as the official language in 26 countries which qualifies it to be an important langauge. Because of that, a lot of textual data written in arabic language is generated whether it's from socail media, a news website or google searches etc... Also, Arabic in its standard form, known as Modern Standard Arabic (MSA), is one of the 6 official languages of the United Nations.\n",
    "\n",
    "Despite its importance and significance in the world, it has yet to have a major breakthrough in the NLP applications. Arabic has received comparatively little attention in modern computational linguistics. It is indeed a challenging topic due to the complexity of the language, its rich morphology, as well as the presence many different dialects. But with the constant advancement in the NLP field, as well as deep learning and big data, and with proper research and dedication, the creation of a great ANLP model will be considered a breakthrough in the computational liguistics.\n",
    "\n",
    "What we proposed in this project is to predict the category of the arabic news using an nlp model, whether it's local news, international, sports related etc... A simple way to benefit from this is to use it, for example, to categorize the huge amount of data coming from Twitter and thus it will be much easier for a client to find the news related to his category in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPI and Metric\n",
    "\n",
    "This predictive model can be integrated in any news providing medium. Some of the benefits and KPIs to help us track the impact of this project:\n",
    "<ul>\n",
    "  <li>Trending category shown at first</li>\n",
    "  <li>Number of users or visits to the medium</li>\n",
    "  <li>User Satisfaction with the medium integrated</li>\n",
    "</ul>\n",
    "\n",
    "The metric that we used to evaluate our performance in the **F1 SCORE**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "As mentioned before, arabic text data is hard to be found, and rare to find one already categorized so, the data that we will be using throughout the project is collected from a Lebanese news website www.lebanonfiles.com . This site contains all sorts of news such as economical, political news ... and what made this part challenging is that we had to extract the data ourselves in order to use it.\n",
    "\n",
    "The data collected:\n",
    "<ul>\n",
    "    <li>Id: integer, identifier for the news</li>\n",
    "    <li>Title: string, title of the news which can tell a lot about the category</li>\n",
    "    <li>Date: date type, but written in arabic</li>\n",
    "    <li>Desc: string, description of the news</li>\n",
    "    <li>Image: string, some news may contain an image</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import datetime\n",
    "import dateutil.parser as dparser\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import unicodedata as ud\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import get_train_data\n",
    "X_df, y_array = get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1313318</td>\n",
       "      <td>تكريم الشاعر موسى زغي ورئيس الجمهورية قلده وسا...</td>\n",
       "      <td>الخميس 12 نيسان 2018 - 15:37</td>\n",
       "      <td>\\n\\r\\n\\tكرمت جامعة الروح القدس - الكسليك وجامع...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/12-04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1413607</td>\n",
       "      <td>نائب معارض لمادورو: حزب الله يستثمر منجمين للذ...</td>\n",
       "      <td>الاثنين 14 كانون الثاني 2019 - 15:58</td>\n",
       "      <td>\\n\\n\\tكشف نائب معارض للرئيس الفنزويلي نيكولاس ...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/14-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1363260</td>\n",
       "      <td>هكذا استغل داعش الأطفال في هجمات الشيشان</td>\n",
       "      <td>الخميس 23 آب 2018 - 07:29</td>\n",
       "      <td>\\n\\n\\tنشر تنظيم داعش مقطع فيديو، الأربعاء، يظه...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/23-08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>971779</td>\n",
       "      <td>سلام ترأس اجتماعا لخلية الازمة الوزارية</td>\n",
       "      <td>الاثنين 07 كانون الأول 2015 - 18:48</td>\n",
       "      <td>\\n\\r\\n\\tترأس رئيس مجلس الوزراء تمام سلام اجتما...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/07-12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>960499</td>\n",
       "      <td>كنعان: وصلنا الى اتفاق حول اقتراح قانون استعاد...</td>\n",
       "      <td>الأربعاء 11 تشرين الثاني 2015 - 15:01</td>\n",
       "      <td>\\n\\r\\n\\tعقد نواب من \"التيار الوطني الحر\" والمس...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/11-11...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              Title  \\\n",
       "0  1313318  تكريم الشاعر موسى زغي ورئيس الجمهورية قلده وسا...   \n",
       "1  1413607  نائب معارض لمادورو: حزب الله يستثمر منجمين للذ...   \n",
       "2  1363260           هكذا استغل داعش الأطفال في هجمات الشيشان   \n",
       "3   971779            سلام ترأس اجتماعا لخلية الازمة الوزارية   \n",
       "4   960499  كنعان: وصلنا الى اتفاق حول اقتراح قانون استعاد...   \n",
       "\n",
       "                                    Date  \\\n",
       "0           الخميس 12 نيسان 2018 - 15:37   \n",
       "1   الاثنين 14 كانون الثاني 2019 - 15:58   \n",
       "2              الخميس 23 آب 2018 - 07:29   \n",
       "3    الاثنين 07 كانون الأول 2015 - 18:48   \n",
       "4  الأربعاء 11 تشرين الثاني 2015 - 15:01   \n",
       "\n",
       "                                                Desc  \\\n",
       "0  \\n\\r\\n\\tكرمت جامعة الروح القدس - الكسليك وجامع...   \n",
       "1  \\n\\n\\tكشف نائب معارض للرئيس الفنزويلي نيكولاس ...   \n",
       "2  \\n\\n\\tنشر تنظيم داعش مقطع فيديو، الأربعاء، يظه...   \n",
       "3  \\n\\r\\n\\tترأس رئيس مجلس الوزراء تمام سلام اجتما...   \n",
       "4  \\n\\r\\n\\tعقد نواب من \"التيار الوطني الحر\" والمس...   \n",
       "\n",
       "                                               Image  \n",
       "0  http://www.lebanonfiles.com/files/images/12-04...  \n",
       "1  http://www.lebanonfiles.com/files/images/14-01...  \n",
       "2  http://www.lebanonfiles.com/files/images/23-08...  \n",
       "3  http://www.lebanonfiles.com/files/images/07-12...  \n",
       "4  http://www.lebanonfiles.com/files/images/11-11...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = int(len(X_df) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = X_df[:length]\n",
    "y_array = y_array[:length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the arabic date to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_date(x):\n",
    "    dicta =  {\"كانون الثاني\": \"january\" ,\"شباط\": \"february\", \"أيار\": \"may\",  \"نيسان\": \"April\",\n",
    "         \"آذار\": \"march\", \"حزيران\": \"june\", \"تموز\": \"july\", \"آب\": \"august\", \"أيلول\": \"september\",\n",
    "         \"تشرين الأول\": \"october\", \"تشرين الثاني\": \"november\", \"كانون الأول\": \"december\",\n",
    "         \"الاثنين\": \"monday\", \"الثلاثاء\": \"tuesday\", \"الأربعاء\": \"wednesday\", \"الخميس\": \"thursday\", \"الجمعة\": \"friday\",\n",
    "         \"السبت\": \"saturday\", \"الأحد\": \"sunday\", \"السبت\": \"saturday\"}\n",
    "    x_new = x\n",
    "    for arabic, english in dicta.items():\n",
    "        x_new = x_new.replace(arabic, english)\n",
    "    x_new = dparser.parse(x_new, fuzzy=True)\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1313318</td>\n",
       "      <td>تكريم الشاعر موسى زغي ورئيس الجمهورية قلده وسا...</td>\n",
       "      <td>2018-04-12 15:37:00</td>\n",
       "      <td>\\n\\r\\n\\tكرمت جامعة الروح القدس - الكسليك وجامع...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/12-04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1413607</td>\n",
       "      <td>نائب معارض لمادورو: حزب الله يستثمر منجمين للذ...</td>\n",
       "      <td>2019-01-14 15:58:00</td>\n",
       "      <td>\\n\\n\\tكشف نائب معارض للرئيس الفنزويلي نيكولاس ...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/14-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1363260</td>\n",
       "      <td>هكذا استغل داعش الأطفال في هجمات الشيشان</td>\n",
       "      <td>2018-08-23 07:29:00</td>\n",
       "      <td>\\n\\n\\tنشر تنظيم داعش مقطع فيديو، الأربعاء، يظه...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/23-08...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              Title  \\\n",
       "0  1313318  تكريم الشاعر موسى زغي ورئيس الجمهورية قلده وسا...   \n",
       "1  1413607  نائب معارض لمادورو: حزب الله يستثمر منجمين للذ...   \n",
       "2  1363260           هكذا استغل داعش الأطفال في هجمات الشيشان   \n",
       "\n",
       "                 Date                                               Desc  \\\n",
       "0 2018-04-12 15:37:00  \\n\\r\\n\\tكرمت جامعة الروح القدس - الكسليك وجامع...   \n",
       "1 2019-01-14 15:58:00  \\n\\n\\tكشف نائب معارض للرئيس الفنزويلي نيكولاس ...   \n",
       "2 2018-08-23 07:29:00  \\n\\n\\tنشر تنظيم داعش مقطع فيديو، الأربعاء، يظه...   \n",
       "\n",
       "                                               Image  \n",
       "0  http://www.lebanonfiles.com/files/images/12-04...  \n",
       "1  http://www.lebanonfiles.com/files/images/14-01...  \n",
       "2  http://www.lebanonfiles.com/files/images/23-08...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df['Date'] = X_df.Date.apply(convert_to_date)\n",
    "X_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11640, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id       0.000000\n",
       "Title    0.000000\n",
       "Date     0.000000\n",
       "Desc     0.000515\n",
       "Image    0.037113\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proportion of NaN values\n",
    "X_df.isna().sum() / X_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id       11640\n",
       "Title    11616\n",
       "Date     11582\n",
       "Desc     11634\n",
       "Image    11182\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique values\n",
    "X_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                int64\n",
       "Title            object\n",
       "Date     datetime64[ns]\n",
       "Desc             object\n",
       "Image            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.164000e+04</td>\n",
       "      <td>11640</td>\n",
       "      <td>11640</td>\n",
       "      <td>11634</td>\n",
       "      <td>11208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11616</td>\n",
       "      <td>11582</td>\n",
       "      <td>11634</td>\n",
       "      <td>11182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>الدفاع المدني: مهمات إنقاذ وإسعاف وإخماد حرائق...</td>\n",
       "      <td>2015-08-27 16:50:00</td>\n",
       "      <td>\\n\\n\\tكشفت مصادر مطلعة للـ\"أم تي في\"، أن \"رئيس...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/10-02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-06-21 12:24:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-15 08:25:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.282918e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.243605e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000080e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.982312e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.371369e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.459972e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.560309e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id                                              Title  \\\n",
       "count   1.164000e+04                                              11640   \n",
       "unique           NaN                                              11616   \n",
       "top              NaN  الدفاع المدني: مهمات إنقاذ وإسعاف وإخماد حرائق...   \n",
       "freq             NaN                                                 12   \n",
       "first            NaN                                                NaN   \n",
       "last             NaN                                                NaN   \n",
       "mean    1.282918e+06                                                NaN   \n",
       "std     2.243605e+05                                                NaN   \n",
       "min     9.000080e+05                                                NaN   \n",
       "25%     9.982312e+05                                                NaN   \n",
       "50%     1.371369e+06                                                NaN   \n",
       "75%     1.459972e+06                                                NaN   \n",
       "max     1.560309e+06                                                NaN   \n",
       "\n",
       "                       Date  \\\n",
       "count                 11640   \n",
       "unique                11582   \n",
       "top     2015-08-27 16:50:00   \n",
       "freq                      2   \n",
       "first   2015-06-21 12:24:00   \n",
       "last    2020-01-15 08:25:00   \n",
       "mean                    NaN   \n",
       "std                     NaN   \n",
       "min                     NaN   \n",
       "25%                     NaN   \n",
       "50%                     NaN   \n",
       "75%                     NaN   \n",
       "max                     NaN   \n",
       "\n",
       "                                                     Desc  \\\n",
       "count                                               11634   \n",
       "unique                                              11634   \n",
       "top     \\n\\n\\tكشفت مصادر مطلعة للـ\"أم تي في\"، أن \"رئيس...   \n",
       "freq                                                    1   \n",
       "first                                                 NaN   \n",
       "last                                                  NaN   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                                    Image  \n",
       "count                                               11208  \n",
       "unique                                              11182  \n",
       "top     http://www.lebanonfiles.com/files/images/10-02...  \n",
       "freq                                                    3  \n",
       "first                                                 NaN  \n",
       "last                                                  NaN  \n",
       "mean                                                  NaN  \n",
       "std                                                   NaN  \n",
       "min                                                   NaN  \n",
       "25%                                                   NaN  \n",
       "50%                                                   NaN  \n",
       "75%                                                   NaN  \n",
       "max                                                   NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['أخبار محليّة', 'أخبار فنية', 'أخبار اقتصادية ومالية', 'أخبار رياضية', 'أخبار إقليمية ودولية']\n",
    "class2index = dict(zip(categories, range(len(categories))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_array = np.array([class2index[cat] for cat in y_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7147.,    0.,  842.,    0.,    0.,  946.,    0.,  745.,    0.,\n",
       "        1960.]),\n",
       " array([0. , 0.4, 0.8, 1.2, 1.6, 2. , 2.4, 2.8, 3.2, 3.6, 4. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see the data is unbalanced so as scorer we use the F1 Score as scorer dor our challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive fill for the \"Desc\" Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_df['Desc'] = X_df['Desc'].astype('str')\n",
    "X_df.loc[X_df['Desc']=='', 'Desc'] = X_df['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1313318</td>\n",
       "      <td>تكريم الشاعر موسى زغي ورئيس الجمهورية قلده وسا...</td>\n",
       "      <td>2018-04-12 15:37:00</td>\n",
       "      <td>\\n\\r\\n\\tكرمت جامعة الروح القدس - الكسليك وجامع...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/12-04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1413607</td>\n",
       "      <td>نائب معارض لمادورو: حزب الله يستثمر منجمين للذ...</td>\n",
       "      <td>2019-01-14 15:58:00</td>\n",
       "      <td>\\n\\n\\tكشف نائب معارض للرئيس الفنزويلي نيكولاس ...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/14-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1363260</td>\n",
       "      <td>هكذا استغل داعش الأطفال في هجمات الشيشان</td>\n",
       "      <td>2018-08-23 07:29:00</td>\n",
       "      <td>\\n\\n\\tنشر تنظيم داعش مقطع فيديو، الأربعاء، يظه...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/23-08...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              Title  \\\n",
       "0  1313318  تكريم الشاعر موسى زغي ورئيس الجمهورية قلده وسا...   \n",
       "1  1413607  نائب معارض لمادورو: حزب الله يستثمر منجمين للذ...   \n",
       "2  1363260           هكذا استغل داعش الأطفال في هجمات الشيشان   \n",
       "\n",
       "                 Date                                               Desc  \\\n",
       "0 2018-04-12 15:37:00  \\n\\r\\n\\tكرمت جامعة الروح القدس - الكسليك وجامع...   \n",
       "1 2019-01-14 15:58:00  \\n\\n\\tكشف نائب معارض للرئيس الفنزويلي نيكولاس ...   \n",
       "2 2018-08-23 07:29:00  \\n\\n\\tنشر تنظيم داعش مقطع فيديو، الأربعاء، يظه...   \n",
       "\n",
       "                                               Image  \n",
       "0  http://www.lebanonfiles.com/files/images/12-04...  \n",
       "1  http://www.lebanonfiles.com/files/images/14-01...  \n",
       "2  http://www.lebanonfiles.com/files/images/23-08...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the \"Desc\" and \"Title\" column (remove \\t, weird symbols and stop words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stps_arabic = set(stopwords.words('arabic'))\n",
    "arabic_diacritics = re.compile(\"\"\"\n",
    "                             ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "\n",
    "def clean_txt(sent):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"    \n",
    "    text = sent.strip()\n",
    "    text = re.sub('[\\n\\r\\t\\xa0]', ' ', text)\n",
    "    text = re.sub(arabic_diacritics, '', text)\n",
    "    text = ''.join(c for c in text if not ud.category(c).startswith('P') and not c.isdigit())\n",
    "    res = re.sub(' +', ' ', text)\n",
    "    return [w for w in text.split() if w not in stps_arabic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df['Title'] = X_df['Title'].apply(clean_txt)\n",
    "X_df['Desc'] = X_df['Desc'].apply(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1313318</td>\n",
       "      <td>[تكريم, الشاعر, موسى, زغي, ورئيس, الجمهورية, ق...</td>\n",
       "      <td>2018-04-12 15:37:00</td>\n",
       "      <td>[كرمت, جامعة, الروح, القدس, الكسليك, وجامعة, آ...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/12-04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1413607</td>\n",
       "      <td>[نائب, معارض, لمادورو, حزب, الله, يستثمر, منجم...</td>\n",
       "      <td>2019-01-14 15:58:00</td>\n",
       "      <td>[كشف, نائب, معارض, للرئيس, الفنزويلي, نيكولاس,...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/14-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1363260</td>\n",
       "      <td>[استغل, داعش, الأطفال, هجمات, الشيشان]</td>\n",
       "      <td>2018-08-23 07:29:00</td>\n",
       "      <td>[نشر, تنظيم, داعش, مقطع, فيديو, الأربعاء, يظهر...</td>\n",
       "      <td>http://www.lebanonfiles.com/files/images/23-08...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              Title  \\\n",
       "0  1313318  [تكريم, الشاعر, موسى, زغي, ورئيس, الجمهورية, ق...   \n",
       "1  1413607  [نائب, معارض, لمادورو, حزب, الله, يستثمر, منجم...   \n",
       "2  1363260             [استغل, داعش, الأطفال, هجمات, الشيشان]   \n",
       "\n",
       "                 Date                                               Desc  \\\n",
       "0 2018-04-12 15:37:00  [كرمت, جامعة, الروح, القدس, الكسليك, وجامعة, آ...   \n",
       "1 2019-01-14 15:58:00  [كشف, نائب, معارض, للرئيس, الفنزويلي, نيكولاس,...   \n",
       "2 2018-08-23 07:29:00  [نشر, تنظيم, داعش, مقطع, فيديو, الأربعاء, يظهر...   \n",
       "\n",
       "                                               Image  \n",
       "0  http://www.lebanonfiles.com/files/images/12-04...  \n",
       "1  http://www.lebanonfiles.com/files/images/14-01...  \n",
       "2  http://www.lebanonfiles.com/files/images/23-08...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SpatialDropout1D, LSTM, Dense\n",
    "import keras.backend as K\n",
    "\n",
    "# The maximum number of words to be used. (Most frequent)\n",
    "vocab_size = 20000\n",
    "\n",
    "# The padding and truncating types used.\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "\n",
    "# The OOV token (Out Of Vocabulary) will be included within the dictionary\n",
    "oov_tok = '<OOV>'\n",
    "\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 200\n",
    "\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X_df['Desc'].values)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(X_df['Desc'])\n",
    "X = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   35,     7,   157,   583,   135,     6,     3, 11470,  2164,\n",
       "        1909,  1750,   753,  3424, 12633,    68,   137, 17501,  1750,\n",
       "        1170,  5496,  5497,  1812,  3132,  4366,  3133,   135,    24,\n",
       "         224,   526,  2599, 11151,   448,  5099,  1750,   753,  8991,\n",
       "         166,   292,     9,    65,     1,     7,   135,  5099,  1750,\n",
       "         753,    98,    50,    89,   630,  2279,  4040,     1,  5173,\n",
       "          29,  1750,   753,   946,     1,   166,     1,   161, 15261,\n",
       "        3468,   154,   723,     1,    95,    29,   704,   797,  1647,\n",
       "         166,     1,     1,     1,  3990,   268,  4366,  2722,     1,\n",
       "         174,     1,   294,     1,   371,  5252,  1677,  1750,   753,\n",
       "       17501,  6131,  7574,  6132,   135,     1,  3215,  7891,  6347,\n",
       "          61,   132,   102,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "قال الرئيس الأميركي دونالد ترامب اليوم ان إدارته تجري محادثات كوريا الجنوبية تزيد تمويلها بشكل كبير لحمايتها كوريا الشمالية تصاعد التوترات شبه الجزيرة الكورية وكتب ترامب عبر تويتر مدى العقود العديدة الماضية دفعت كوريا الجنوبية القليل جدا المال العام الماضي <OOV> الرئيس ترامب دفعت كوريا الجنوبية مليون دولار وأضاف بدأت المحادثات لزيادة <OOV> للولايات المتحدة كوريا الجنوبية بلد <OOV> جدا <OOV> الآن بالتزام المساهمة الدفاع العسكري <OOV> الولايات المتحدة العلاقة البلدين جيدة جدا <OOV> <OOV> <OOV> أمني الحرب الكورية انتهت <OOV> وليس <OOV> سلام <OOV> ألف جندي أميركي كوريا الجنوبية لحمايتها تهديدات بيونغ يانغ ترامب <OOV> مرارا تكاليف إبقاء القوات الأميركية البلد <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "---\n",
      "قال الرئيس الأميركي دونالد ترامب اليوم ان إدارته تجري محادثات كوريا الجنوبية تزيد تمويلها بشكل كبير لحمايتها كوريا الشمالية تصاعد التوترات شبه الجزيرة الكورية وكتب ترامب عبر تويتر مدى العقود العديدة الماضية دفعت كوريا الجنوبية القليل جدا المال العام الماضي وبطلب الرئيس ترامب دفعت كوريا الجنوبية مليون دولار وأضاف بدأت المحادثات لزيادة الدفعات للولايات المتحدة كوريا الجنوبية بلد ثري جدا ويشعر الآن بالتزام المساهمة الدفاع العسكري توفره الولايات المتحدة العلاقة البلدين جيدة جدا والبلدان يرتبطان بتحالف أمني الحرب الكورية انتهت بهدنة وليس بمعاهدة سلام وينتشر ألف جندي أميركي كوريا الجنوبية لحمايتها تهديدات بيونغ يانغ ترامب اشتكى مرارا تكاليف إبقاء القوات الأميركية البلد\n"
     ]
    }
   ],
   "source": [
    "id_to_word = {value:key for key,value in word_index.items()}\n",
    "id_to_word[0] = '<PAD>'\n",
    "print(' '.join(id_to_word[id] for id in X[10]))\n",
    "print('---')\n",
    "print(' '.join(X_df.loc[10]['Desc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Y_train to one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(y_array.reshape(-1, 1))\n",
    "Y_train = enc.transform(y_array.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the f1_score function (not integrated in Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1(y_true, y_pred):\n",
    "    \n",
    "    y_true = K.argmax(y_true, -1)\n",
    "    y_pred = K.argmax(y_pred, -1)\n",
    "    \n",
    "    prec_num = 0\n",
    "    prec_den = 0\n",
    "    recall_num = 0\n",
    "    recall_den = 0\n",
    "    \n",
    "    equal = K.equal(y_true, y_pred)\n",
    "    not_equal = K.not_equal(y_true, y_pred)\n",
    "    \n",
    "    for i in range(5):\n",
    "        prec_num += K.sum(K.cast(K.all(K.stack([equal, K.equal(y_true, i)], axis=0), axis=0), 'int32'))\n",
    "        prec_den += prec_num + K.sum(K.cast(K.all(K.stack([not_equal, K.equal(y_pred, i)], axis=0), axis=0), 'int32'))\n",
    "        recall_num += prec_num\n",
    "        recall_den += prec_num + K.sum(K.cast(K.all(K.stack([not_equal, K.equal(y_true, i)], axis=0), axis=0), 'int32'))\n",
    "        \n",
    "    prec_num = K.cast(prec_num, 'float')\n",
    "    prec_den = K.cast(prec_den, 'float')\n",
    "    recall_num = K.cast(recall_num, 'float')\n",
    "    recall_den = K.cast(recall_den, 'float')\n",
    "    \n",
    "    precision = prec_num / prec_den\n",
    "    recall = recall_num / recall_den\n",
    "    f1_val = 2*(precision * recall)/(precision + recall)\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[get_f1])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 200, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 2,080,905\n",
      "Trainable params: 2,080,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmad/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9894 samples, validate on 1746 samples\n",
      "Epoch 1/10\n",
      "9894/9894 [==============================] - 102s 10ms/step - loss: 1.1945 - get_f1: 0.2946 - val_loss: 1.1640 - val_get_f1: 0.2949\n",
      "Epoch 2/10\n",
      "9894/9894 [==============================] - 94s 10ms/step - loss: 1.0663 - get_f1: 0.3055 - val_loss: 0.9666 - val_get_f1: 0.3319\n",
      "Epoch 3/10\n",
      "9894/9894 [==============================] - 91s 9ms/step - loss: 0.9126 - get_f1: 0.3308 - val_loss: 0.8699 - val_get_f1: 0.3483\n",
      "Epoch 4/10\n",
      "9894/9894 [==============================] - 91s 9ms/step - loss: 0.9054 - get_f1: 0.3355 - val_loss: 0.9260 - val_get_f1: 0.3360\n",
      "Epoch 5/10\n",
      "9894/9894 [==============================] - 90s 9ms/step - loss: 0.8251 - get_f1: 0.3497 - val_loss: 0.8725 - val_get_f1: 0.3508\n",
      "Epoch 6/10\n",
      "9894/9894 [==============================] - 91s 9ms/step - loss: 0.7530 - get_f1: 0.3587 - val_loss: 0.8641 - val_get_f1: 0.3533\n",
      "Epoch 7/10\n",
      "9894/9894 [==============================] - 91s 9ms/step - loss: 0.7371 - get_f1: 0.3593 - val_loss: 0.8922 - val_get_f1: 0.3494\n",
      "Epoch 8/10\n",
      "9894/9894 [==============================] - 93s 9ms/step - loss: 0.7585 - get_f1: 0.3546 - val_loss: 0.8850 - val_get_f1: 0.3526\n",
      "Epoch 9/10\n",
      "9894/9894 [==============================] - 95s 10ms/step - loss: 0.6837 - get_f1: 0.3662 - val_loss: 0.9039 - val_get_f1: 0.3510\n",
      "Epoch 10/10\n",
      "9894/9894 [==============================] - 93s 9ms/step - loss: 0.6728 - get_f1: 0.3676 - val_loss: 0.8630 - val_get_f1: 0.3633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f1ec867dfd0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11640/11640 [==============================] - 33s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6379385566588529, 0.3775031864643097]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 4, 0, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 4, ..., 1, 0, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Y_train, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import get_test_data\n",
    "X_test, y_test = get_test_data()\n",
    "X_test['Date'] = X_test['Date'].apply(convert_to_date)\n",
    "X_test['Title'] = X_test['Title'].astype('str')\n",
    "X_test['Desc'] = X_test['Desc'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Title'] = X_test['Title'].apply(clean_txt)\n",
    "X_test['Desc'] = X_test['Desc'].apply(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(X_test['Desc'])\n",
    "X_test = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([class2index[cat] for cat in y_test])\n",
    "\n",
    "Y_test = enc.transform(y_test.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38804/38804 [==============================] - 111s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8461193945061091, 0.3626594543457031]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import get_train_data\n",
    "X_df, y_array = get_train_data()\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='median'))])\n",
    "\n",
    "def convert_to_date(x):\n",
    "    dicta =  {\"كانون الثاني\": \"january\" ,\"شباط\": \"february\", \"أيار\": \"may\",  \"نيسان\": \"April\",\n",
    "        \"آذار\": \"march\", \"حزيران\": \"june\", \"تموز\": \"july\", \"آب\": \"august\", \"أيلول\": \"september\",\n",
    "        \"تشرين الأول\": \"october\", \"تشرين الثاني\": \"november\", \"كانون الأول\": \"december\",\n",
    "        \"الاثنين\": \"monday\", \"الثلاثاء\": \"tuesday\", \"الأربعاء\": \"wednesday\", \"الخميس\": \"thursday\", \"الجمعة\": \"friday\",\n",
    "        \"السبت\": \"saturday\", \"الأحد\": \"sunday\", \"السبت\": \"saturday\"}\n",
    "    x_new = x\n",
    "    for arabic, english in dicta.items():\n",
    "        x_new = x_new.replace(arabic, english)\n",
    "    x_new = dparser.parse(x_new, fuzzy=True)\n",
    "    return x_new\n",
    "def process_date(X):\n",
    "    date = X.Date.apply(convert_to_date)\n",
    "    return np.c_[date.dt.year, date.dt.month, date.dt.day]\n",
    "date_transformer = FunctionTransformer(process_date, validate=False)\n",
    "\n",
    "\n",
    "def clean_txt(sent):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        return: modified initial string\n",
    "    \"\"\"    \n",
    "    stps_arabic = set(stopwords.words('arabic'))\n",
    "    arabic_diacritics = re.compile(\"\"\"\n",
    "                                ّ    | # Tashdid\n",
    "                                َ    | # Fatha\n",
    "                                ً    | # Tanwin Fath\n",
    "                                ُ    | # Damma\n",
    "                                ٌ    | # Tanwin Damm\n",
    "                                ِ    | # Kasra\n",
    "                                ٍ    | # Tanwin Kasr\n",
    "                                ْ    | # Sukun\n",
    "                                ـ     # Tatwil/Kashida\n",
    "                            \"\"\", re.VERBOSE)\n",
    "    sent = str(sent)\n",
    "    text = sent.strip()\n",
    "    text = re.sub('[\\n\\r\\t\\xa0]', ' ', text)\n",
    "    text = re.sub(arabic_diacritics, '', text)\n",
    "    text = ''.join(c for c in text if not ud.category(c).startswith('P') and not c.isdigit())\n",
    "    res = re.sub(' +', ' ', text)\n",
    "    return [w for w in text.split() if w not in stps_arabic]\n",
    "\n",
    "def process_text(X):\n",
    "    X.loc[X['Desc']=='', 'Desc'] = X['Title']\n",
    "    X['Title'] = X['Title'].apply(clean_txt)\n",
    "    X['Desc'] = X['Desc'].apply(clean_txt)\n",
    "    return np.c_[ X['Title'], X['Desc']]\n",
    "\n",
    "\n",
    "num_col = ['Id']\n",
    "date_col = ['Date']\n",
    "drop_cols = ['Image', 'Title', 'Desc']\n",
    "\n",
    "non_text_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('date', make_pipeline(date_transformer), date_col),\n",
    "        ('num', numeric_transformer, num_col),\n",
    "        ('drop cols', 'drop', drop_cols),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array = non_text_preprocessor.fit_transform(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.018000e+03, 4.000000e+00, 1.200000e+01, 1.313318e+06],\n",
       "       [2.019000e+03, 1.000000e+00, 1.400000e+01, 1.413607e+06],\n",
       "       [2.018000e+03, 8.000000e+00, 2.300000e+01, 1.363260e+06],\n",
       "       ...,\n",
       "       [2.019000e+03, 2.000000e+00, 2.000000e+00, 1.422303e+06],\n",
       "       [2.019000e+03, 7.000000e+00, 8.000000e+00, 1.481177e+06],\n",
       "       [2.019000e+03, 1.000000e+00, 7.000000e+00, 1.410380e+06]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_text(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
