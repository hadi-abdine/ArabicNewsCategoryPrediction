{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "<table style=\"width:100%; background-color:transparent;\">\n",
    "  <tr style=\"background-color:transparent;\">\n",
    "    <td style=\"background-color:transparent;\"><a href=\"http://www.datascience-paris-saclay.fr\">\n",
    "<img border=\"0\" src=\"http://project.inria.fr/saclaycds/files/2017/02/logoUPSayPlusCDS_990.png\" width=\"90%\"> </td>\n",
    "     <td style=\"background-color:transparent;\"><a href=\"https://www.sidetrade.com/\">\n",
    "<img border=\"0\" src=\"https://www.sidetrade.com/wp-content/uploads/22050384_10213210110060640_1095182809_o-300x117.png\" width=\"60%\"> </td>\n",
    "  </tr>\n",
    "</table> \n",
    "</div>\n",
    "\n",
    "<center><h1>FAN revenue prediction challenge</h1></center>\n",
    "<br/>\n",
    "<center>Lucy Liu (CDS), Maria Teleczuk (CDS), Clément Chastagnol (Sidetrade),<br /> Gael Varoquaux (Inria, Parietal), Alex Gramfort (Inria, Parietal), Guillaume Lemaitre (Scikit-learn @ Inria Foundation)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting revenue using French Attribution Notices: [RAMP studio challenge](https://ramp.studio/problems/fan_revenue_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "0. [Introduction](#Introduction)\n",
    "1. [Data](#Data)\n",
    "3. [Score metric](#Score-metric)\n",
    "4. [Data exploration](#Data-exploration)\n",
    "5. [Predictions](#Predictions)\n",
    "6. [Record linkage](#Record-linkage)\n",
    "7. [Submission structure](#Submission-structure)\n",
    "8. [Local testing](#Local-testing-(before-submission))\n",
    "9. [Submitting to RAMP studio](#Submitting-to-[ramp.studio](http://ramp.studio))\n",
    "10. [More information](#More-information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The objective of this challenge is to work with 'dirty data'. Most real data is dirty and the availability of high-quality, open-source ML and data analysis frameworks (such as [scikit-learn](https://scikit-learn.org/),\n",
    "[pandas](https://pandas.pydata.org/)...) means that the next frontier for tooling and automation lies in preprocessing. This challenge aims to investigate methodologies to perform statistical analysis directly on the original dirty data.\n",
    "\n",
    "There are two datasets in this challenge:\n",
    "\n",
    "* `company_revenue_TRAIN.csv` - company revenue declarations.\n",
    "* `award_notices_RAMP.csv` -  French Attribution Notices.\n",
    "\n",
    "# Aim\n",
    "\n",
    "The predictive aim of this challenge is to use `company_revenue_TRAIN.csv` and `award_notices_RAMP.csv` to predict the Revenue for each entry in the 'company financial data' dataset. It is advised that you use both datasets, as it improves the prediction (see [Score comparison](#Score-comparison)), but using only the `company_revenue_TRAIN.csv` dataset is also allowed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "## Company financial data\n",
    "\n",
    "This dataset was built from an extract of the [National Institute of Statistics and Economic Studies (INSEE)](https://www.insee.fr/en/accueil) reference database of company revenue declarations from 2013 to 2018. Each row represents the declaration of one company for one year and the following information is provided in the columns:\n",
    "\n",
    "* `Legal_ID` - the reconcilled legal ID of the company\n",
    "* `Name` - the name of the company\n",
    "* `Activity_code (APE)` - 'Activite Principale de l'Entreprise', the main activity of the company - more information in [English](https://www.startbusinessinfrance.com/code-ape) or in [French](https://www.service-public.fr/professionnels-entreprises/vosdroits/F33050)\n",
    "* `Address` \n",
    "* `Zipcode`\n",
    "* `City`\n",
    "* `Revenue` - in Euros\n",
    "* `Headcount`\n",
    "* `Fiscal_year_end_date`\n",
    "* `Fiscal_year_duration_in_months`\n",
    "* `Year`\n",
    "\n",
    "There are a few things to note:\n",
    "\n",
    "* there are revenue declarations for the same company but different years\n",
    "* there is a large reduction in entries for the years 2017 and 2018 due to the Loi Macron law in 2017\n",
    "* the 'same company' can have several different entities, resulting in entries where the `Legal_ID` is different but the `Name`, `Address`, `City` and `Zipcode` are all the same.\n",
    "* `Revenue` can be negative. A negative revenue may be due to cancelled orders from the previous fiscal year that was recorded in the current fiscal year.\n",
    "\n",
    "\n",
    "## Award notices\n",
    "\n",
    "Every French public organisation has to issue a call for tenders when buying supplies or services (above a minimum threshold). These are called public procurement contracts. Companies then compete anonymously on these contracts and when a bid is awarded, a notice has to be legally published by the public organization on the [BOAMP](https://www.boamp.fr/) (historical data is hosted by the [DILA](https://www.dila.premier-ministre.gouv.fr/)). These are called French Attribution Notices (FAN). About 25% of awards are actually electronically published.\n",
    "\n",
    "Each contract can be divided into a maximum of 5 lots and the same company can win >1 lot of a contract. The award notices dataset comprises award notices from 2017 and 2018. Each row refers to one lot and there can be up to 5 lots referring to the same contract. The following information is provided for each lot:\n",
    "\n",
    "* `ID_call` - ID of the award notice\n",
    "* `Publication_date` of the award notice\n",
    "* `End_of_call_date` of the award notice\n",
    "* `Departments_of_publication` - the department code(s) of the award notice\n",
    "* `Department_of_provision` - the department code(s) where the contract works/goods/services were provided \n",
    "* `Call_summary` - summary of the award notice\n",
    "* `Call_title` - title of the award notice\n",
    "* `Complete_call_description` - description of the award notice\n",
    "* `Total_amount` - total amount of the contract, from all lots, in euros\n",
    "* `CPV_classes` - Common Procurement Vocabulary (CPV), a classification system for public procurement used to describe the subject of procurement contracts (more information can be found [here](https://simap.ted.europa.eu/cpv))\n",
    "Columns providing details about the company issuing the contract:\n",
    "* `Buyer_name` \n",
    "* `Buyer_address`\n",
    "* `Buyer_zipcode`\n",
    "* `Buyer_city`\n",
    "* `Buyer_email`\n",
    "* `Buyer_URL`\n",
    "\n",
    "* `Contract_awarded` - whether or not the contact was awarded\n",
    "\n",
    "Columns providing details about the winner of each lot:\n",
    "\n",
    "* `ID` - unique lot ID \n",
    "* `awarded` - whether or not the contact was awarded\n",
    "* `description` - description of the lot\n",
    "* `incumbent_name` - name of the lot winnter\n",
    "* `incumbent_address` - address of the lot winner\n",
    "* `incumbent_zipcode` - zipcode of the lot winner\n",
    "* `incumbent_city` - city of the lot winner\n",
    "* `incumbent_country` - country of the lot winner\n",
    "* `number_of_received_bids` - number of bids this lot received\n",
    "* `amount` - amount of the lot in euros\n",
    "\n",
    "**Important notes**\n",
    "\n",
    "Both data sets are very dirty. There is a lot of missing data and the column descriptions provided above are a guide only. Further, the award notices dataset is much smaller than the company revenue declarations dataset. Therefore, it is expected that many companies in the company revenue declarations dataset are not present in the award notices dataset.\n",
    "\n",
    "## Training and test\n",
    "\n",
    "The company revenue training dataset has been split into 'training' and 'test' subsets. The shapes are:\n",
    "\n",
    "* training: (1 495 948, 11)\n",
    "* test: (520 966, 11)\n",
    "\n",
    "Your model will be tested on a completely separate company revenue dataset stored on the RAMP server. This dataset has a shape of (702 181, 11). This test dataset will also be dirty but we can guarantee that the following columns will (only) be of numerical data type:\n",
    "\n",
    "* `Legal_ID`\n",
    "* `Headcount`\n",
    "* `Fiscal_year_duration_in_months`\n",
    "* `Year`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score metric\n",
    "\n",
    "A unique score is used:\n",
    "\n",
    "$$score =  |max(5,log_{10}(max(1,y\\_true))) - max(5,log_{10}(max(1,y\\_pred)))| $$\n",
    "\n",
    "Score interpretation:\n",
    "\n",
    "* A lower score is better\n",
    "* Any `y_true` or `y_pred` value less than 1 is 'taken' as 1\n",
    "* If both the `y_true` and `y_pred` are less than 100 000, the score would be 0.\n",
    "* The score is the same regardless of the order of `y_true` and `y_pred` in the equation.\n",
    "* If the difference in raw `y_true` and `y_pred` values is the same, the score is greater for smaller magnitudes of `y_true` and `y_pred`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import imp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Company financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import get_train_data\n",
    "\n",
    "X_df, y_array = get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Legal_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Activity_code (APE)</th>\n",
       "      <th>Address</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>City</th>\n",
       "      <th>Headcount</th>\n",
       "      <th>Fiscal_year_end_date</th>\n",
       "      <th>Fiscal_year_duration_in_months</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582296</td>\n",
       "      <td>COMICOB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOULOUPARIS BP 15 BOULOUPARIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>582981</td>\n",
       "      <td>CIANFARANI JEAN-MICHEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33 AVENUE H. LAFLEUR - VICTOIRE - B.P. 4031 NO...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>588541</td>\n",
       "      <td>OK POULET 5EME SARL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23 RUE PAUL BERT</td>\n",
       "      <td>98800.0</td>\n",
       "      <td>NOUMEA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Legal_ID                    Name Activity_code (APE)  \\\n",
       "0    582296                 COMICOB                 NaN   \n",
       "1    582981  CIANFARANI JEAN-MICHEL                 NaN   \n",
       "2    588541     OK POULET 5EME SARL                 NaN   \n",
       "\n",
       "                                             Address  Zipcode    City  \\\n",
       "0                      BOULOUPARIS BP 15 BOULOUPARIS      NaN     NaN   \n",
       "1  33 AVENUE H. LAFLEUR - VICTOIRE - B.P. 4031 NO...      NaN     NaN   \n",
       "2                                   23 RUE PAUL BERT  98800.0  NOUMEA   \n",
       "\n",
       "   Headcount Fiscal_year_end_date  Fiscal_year_duration_in_months    Year  \n",
       "0        NaN           2016-12-31                            12.0  2016.0  \n",
       "1        NaN           2016-12-31                            12.0  2016.0  \n",
       "2        1.0           2016-12-31                            12.0  2016.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df['Fiscal_year_end_date'] = pd.to_datetime(X_df['Fiscal_year_end_date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1495948, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Legal_ID                          0.000000\n",
       "Name                              0.000002\n",
       "Activity_code (APE)               0.012293\n",
       "Address                           0.175296\n",
       "Zipcode                           0.167944\n",
       "City                              0.000313\n",
       "Headcount                         0.637439\n",
       "Fiscal_year_end_date              0.000000\n",
       "Fiscal_year_duration_in_months    0.000000\n",
       "Year                              0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proportion of NaN values\n",
    "X_df.isna().sum() / X_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Legal_ID                          563929\n",
       "Name                              528646\n",
       "Activity_code (APE)                  964\n",
       "Address                           276152\n",
       "Zipcode                             7471\n",
       "City                               29498\n",
       "Headcount                           2224\n",
       "Fiscal_year_end_date                 300\n",
       "Fiscal_year_duration_in_months         1\n",
       "Year                                   6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique values\n",
    "X_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Legal_ID                                   int64\n",
       "Name                                      object\n",
       "Activity_code (APE)                       object\n",
       "Address                                   object\n",
       "Zipcode                                  float64\n",
       "City                                      object\n",
       "Headcount                                float64\n",
       "Fiscal_year_end_date              datetime64[ns]\n",
       "Fiscal_year_duration_in_months           float64\n",
       "Year                                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Legal_ID</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Headcount</th>\n",
       "      <th>Fiscal_year_duration_in_months</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.495948e+06</td>\n",
       "      <td>1.244713e+06</td>\n",
       "      <td>5.423720e+05</td>\n",
       "      <td>1495948.0</td>\n",
       "      <td>1.495948e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.060829e+08</td>\n",
       "      <td>5.464419e+04</td>\n",
       "      <td>8.736985e+01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.014475e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.417373e+08</td>\n",
       "      <td>2.755171e+04</td>\n",
       "      <td>9.002249e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.246598e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.822960e+05</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>-3.900000e+01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.013000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.149439e+08</td>\n",
       "      <td>3.185000e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.013000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.895445e+08</td>\n",
       "      <td>6.053000e+04</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.014000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.293306e+08</td>\n",
       "      <td>7.511600e+04</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.015000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.999905e+08</td>\n",
       "      <td>9.889500e+04</td>\n",
       "      <td>5.450000e+06</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.018000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Legal_ID       Zipcode     Headcount  \\\n",
       "count  1.495948e+06  1.244713e+06  5.423720e+05   \n",
       "mean   5.060829e+08  5.464419e+04  8.736985e+01   \n",
       "std    1.417373e+08  2.755171e+04  9.002249e+03   \n",
       "min    5.822960e+05  6.000000e+00 -3.900000e+01   \n",
       "25%    4.149439e+08  3.185000e+04  1.000000e+00   \n",
       "50%    4.895445e+08  6.053000e+04  3.000000e+00   \n",
       "75%    5.293306e+08  7.511600e+04  9.000000e+00   \n",
       "max    9.999905e+08  9.889500e+04  5.450000e+06   \n",
       "\n",
       "       Fiscal_year_duration_in_months          Year  \n",
       "count                       1495948.0  1.495948e+06  \n",
       "mean                             12.0  2.014475e+03  \n",
       "std                               0.0  1.246598e+00  \n",
       "min                              12.0  2.013000e+03  \n",
       "25%                              12.0  2.013000e+03  \n",
       "50%                              12.0  2.014000e+03  \n",
       "75%                              12.0  2.015000e+03  \n",
       "max                              12.0  2.018000e+03  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21c04512a90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logRev = np.log10(np.clip(y_array, a_min=1, a_max=None))\n",
    "seaborn.kdeplot(logRev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Award notices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is present in the `data/` directory and is added by default to **all** submissions when submitting to RAMP studio. When testing your submission locally however, it is important to copy this file into the submission directory of the submission you wish to test.\n",
    "\n",
    "For example, the starting kit submission directory (`submissions/starting_kit`) contains a copy of this dataset as it is required for RAMP to work locally. You will not need to upload this data file when you are making a submission. See for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hadi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (4,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CallID</th>\n",
       "      <th>Publication_date</th>\n",
       "      <th>End_of_call_date</th>\n",
       "      <th>Departments_of_publication</th>\n",
       "      <th>Departments_of_provision</th>\n",
       "      <th>Call_summary</th>\n",
       "      <th>Call_title</th>\n",
       "      <th>Complete_call_description</th>\n",
       "      <th>Total_amount</th>\n",
       "      <th>CPV_classes</th>\n",
       "      <th>...</th>\n",
       "      <th>ID</th>\n",
       "      <th>awarded</th>\n",
       "      <th>description</th>\n",
       "      <th>incumbent_name</th>\n",
       "      <th>incumbent_address</th>\n",
       "      <th>incumbent_zipcode</th>\n",
       "      <th>incumbent_city</th>\n",
       "      <th>incumbent_country</th>\n",
       "      <th>number_of_received_bids</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16-119770</td>\n",
       "      <td>2016-08-11 00:00:00</td>\n",
       "      <td>2016-09-20</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mission de maitrise d'oeuvre relative aux trav...</td>\n",
       "      <td>MISSION DE MAITRISE D'OEUVRE RELATIVE AUX TRAV...</td>\n",
       "      <td>MISSION DE MAITRISE D'OEUVRE RELATIVE AUX TRAV...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AI PROJECT</td>\n",
       "      <td>11, avenue de la Capelette</td>\n",
       "      <td>13010</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>FR</td>\n",
       "      <td>13.0</td>\n",
       "      <td>83200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15-46335</td>\n",
       "      <td>2015-03-27 00:00:00</td>\n",
       "      <td>2015-04-25</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>fourniture de réactifs immunosérologiques pour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fourniture de réactifs immunosérologiques pour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33696200 33696500</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Kit pour recherche d'anticorps anti-IBR sur sé...</td>\n",
       "      <td>ID-VET</td>\n",
       "      <td>310 rue Louis Pasteur</td>\n",
       "      <td>34790</td>\n",
       "      <td>Grabels</td>\n",
       "      <td>FR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15-46335</td>\n",
       "      <td>2015-03-27 00:00:00</td>\n",
       "      <td>2015-04-25</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>fourniture de réactifs immunosérologiques pour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fourniture de réactifs immunosérologiques pour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33696200 33696500</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Kit pour recherche d'anticorps anti-IBR sur mé...</td>\n",
       "      <td>IDEXX MONTPELLIER SAS</td>\n",
       "      <td>323 RUE DE LA GALERA</td>\n",
       "      <td>34090</td>\n",
       "      <td>MONTPELLIER</td>\n",
       "      <td>FR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CallID     Publication_date End_of_call_date Departments_of_publication  \\\n",
       "0  16-119770  2016-08-11 00:00:00       2016-09-20                         13   \n",
       "1   15-46335  2015-03-27 00:00:00       2015-04-25                         85   \n",
       "2   15-46335  2015-03-27 00:00:00       2015-04-25                         85   \n",
       "\n",
       "  Departments_of_provision                                       Call_summary  \\\n",
       "0                      NaN  mission de maitrise d'oeuvre relative aux trav...   \n",
       "1                       85  fourniture de réactifs immunosérologiques pour...   \n",
       "2                       85  fourniture de réactifs immunosérologiques pour...   \n",
       "\n",
       "                                          Call_title  \\\n",
       "0  MISSION DE MAITRISE D'OEUVRE RELATIVE AUX TRAV...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "\n",
       "                           Complete_call_description  Total_amount  \\\n",
       "0  MISSION DE MAITRISE D'OEUVRE RELATIVE AUX TRAV...           NaN   \n",
       "1  Fourniture de réactifs immunosérologiques pour...           NaN   \n",
       "2  Fourniture de réactifs immunosérologiques pour...           NaN   \n",
       "\n",
       "         CPV_classes   ...      ID awarded  \\\n",
       "0           71000000   ...     NaN     Yes   \n",
       "1  33696200 33696500   ...       1     Yes   \n",
       "2  33696200 33696500   ...       2     Yes   \n",
       "\n",
       "                                         description         incumbent_name  \\\n",
       "0                                                NaN             AI PROJECT   \n",
       "1  Kit pour recherche d'anticorps anti-IBR sur sé...                 ID-VET   \n",
       "2  Kit pour recherche d'anticorps anti-IBR sur mé...  IDEXX MONTPELLIER SAS   \n",
       "\n",
       "            incumbent_address incumbent_zipcode incumbent_city  \\\n",
       "0  11, avenue de la Capelette             13010      Marseille   \n",
       "1       310 rue Louis Pasteur             34790        Grabels   \n",
       "2        323 RUE DE LA GALERA             34090    MONTPELLIER   \n",
       "\n",
       "   incumbent_country number_of_received_bids   amount  \n",
       "0                 FR                    13.0  83200.0  \n",
       "1                 FR                     2.0      NaN  \n",
       "2                 FR                     2.0      NaN  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "award = pd.read_csv('data/award_notices_RAMP.csv.zip', compression='zip')\n",
    "award.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304098, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "award.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CallID                         object\n",
       "Publication_date               object\n",
       "End_of_call_date               object\n",
       "Departments_of_publication     object\n",
       "Departments_of_provision       object\n",
       "Call_summary                   object\n",
       "Call_title                     object\n",
       "Complete_call_description      object\n",
       "Total_amount                  float64\n",
       "CPV_classes                    object\n",
       "Buyer_name                     object\n",
       "Buyer_address                  object\n",
       "Buyer_zipcode                  object\n",
       "Buyer_city                     object\n",
       "Buyer_email                    object\n",
       "Buyer_URL                      object\n",
       "Contract_awarded               object\n",
       "Lot                             int64\n",
       "ID                             object\n",
       "awarded                        object\n",
       "description                    object\n",
       "incumbent_name                 object\n",
       "incumbent_address              object\n",
       "incumbent_zipcode              object\n",
       "incumbent_city                 object\n",
       "incumbent_country              object\n",
       "number_of_received_bids       float64\n",
       "amount                        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "award.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_amount</th>\n",
       "      <th>Lot</th>\n",
       "      <th>number_of_received_bids</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.121260e+05</td>\n",
       "      <td>304098.000000</td>\n",
       "      <td>220936.000000</td>\n",
       "      <td>2.159540e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.177948e+08</td>\n",
       "      <td>2.073213</td>\n",
       "      <td>4.606900</td>\n",
       "      <td>1.145206e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.712391e+10</td>\n",
       "      <td>1.293831</td>\n",
       "      <td>7.982825</td>\n",
       "      <td>2.288319e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.900000e-05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.967891e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.240000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.821163e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.159775e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.568197e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.674995e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+13</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>727.000000</td>\n",
       "      <td>1.000000e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Total_amount            Lot  number_of_received_bids        amount\n",
       "count  1.121260e+05  304098.000000            220936.000000  2.159540e+05\n",
       "mean   5.177948e+08       2.073213                 4.606900  1.145206e+08\n",
       "std    6.712391e+10       1.293831                 7.982825  2.288319e+10\n",
       "min    9.900000e-05       1.000000                 0.000000  0.000000e+00\n",
       "25%    1.967891e+05       1.000000                 2.000000  3.240000e+04\n",
       "50%    4.821163e+05       2.000000                 3.000000  1.159775e+05\n",
       "75%    1.568197e+06       3.000000                 5.000000  3.674995e+05\n",
       "max    1.000000e+13       5.000000               727.000000  1.000000e+13"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "award.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CallID                        0.000016\n",
       "Publication_date              0.000016\n",
       "End_of_call_date              0.000510\n",
       "Departments_of_publication    0.000016\n",
       "Departments_of_provision      0.674611\n",
       "Call_summary                  0.000016\n",
       "Call_title                    0.346484\n",
       "Complete_call_description     0.005426\n",
       "Total_amount                  0.631283\n",
       "CPV_classes                   0.082602\n",
       "Buyer_name                    0.000016\n",
       "Buyer_address                 0.017484\n",
       "Buyer_zipcode                 0.024084\n",
       "Buyer_city                    0.000016\n",
       "Buyer_email                   0.163766\n",
       "Buyer_URL                     0.211047\n",
       "Contract_awarded              0.000016\n",
       "Lot                           0.000000\n",
       "ID                            0.271015\n",
       "awarded                       0.034907\n",
       "description                   0.512683\n",
       "incumbent_name                0.034943\n",
       "incumbent_address             0.140126\n",
       "incumbent_zipcode             0.103414\n",
       "incumbent_city                0.061280\n",
       "incumbent_country             0.034943\n",
       "number_of_received_bids       0.273471\n",
       "amount                        0.289854\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proportion of NA values\n",
    "award.isna().sum() / award.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Company revenue only\n",
    "\n",
    "First, let's predict using only the `comp` dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a transformer that deals with missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Legal_ID                                   int64\n",
       "Name                                      object\n",
       "Activity_code (APE)                       object\n",
       "Address                                   object\n",
       "Zipcode                                  float64\n",
       "City                                      object\n",
       "Headcount                                float64\n",
       "Fiscal_year_end_date              datetime64[ns]\n",
       "Fiscal_year_duration_in_months           float64\n",
       "Year                                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of numerical columns\n",
    "num_cols = ['Legal_ID', 'Headcount', 'Fiscal_year_duration_in_months', 'Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='median'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a transformer to split `Fiscal_year_end_date` into separate year, month, day columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def process_date(X):\n",
    "    date = pd.to_datetime(X['Fiscal_year_end_date'], format='%Y-%m-%d')\n",
    "    return np.c_[date.dt.year, date.dt.month, date.dt.day]\n",
    "\n",
    "date_transformer = FunctionTransformer(process_date, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Process the `Activity_code (APE)` column. At the moment the Scikit learn `OrdinalEncoder()` does not have a `handle_unknown` argument. This means that it would not be able to handle any values in `Activity_code (APE)` which appear in 'train' but do not appear in 'test'. Here we will simply get around this by using the first 2 characters of `APE`, which are always numbers. The first 2 numbers give the broad category the companies activities fall under (e.g. 'AGRICULTURE'). This column is then converted to numeric data type, so missing values can be dealt with by using the median value (with `SimpleImputer()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_APE(X):\n",
    "    APE = X['Activity_code (APE)'].str[:2]\n",
    "    return pd.to_numeric(APE, errors='coerce').values[:, np.newaxis]\n",
    "\n",
    "APE_transformer = FunctionTransformer(process_APE, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Only keep the numbers in the `Zipcode` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipcodes(X):\n",
    "    zipcode_nums = pd.to_numeric(X['Zipcode'], errors='coerce')\n",
    "    return zipcode_nums.values[:, np.newaxis]\n",
    "\n",
    "zipcode_transformer = FunctionTransformer(zipcodes, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the full pipeline is assembled. \n",
    "\n",
    "* for missing values in numerical columns, the 'median' is used.\n",
    "* the date column `Fiscal_year_end_date` is transformed into separated year month and day columns.\n",
    "* `Activity_code (APE)` is dealt with as described above.\n",
    "* the columns `Name`, `Address` and `City` are all dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "zipcode_col = ['Zipcode']\n",
    "date_cols = ['Fiscal_year_end_date']\n",
    "drop_cols = ['Name', 'Address', 'City']\n",
    "APE_col = ['Activity_code (APE)']\n",
    "\n",
    "\n",
    "preprocessor_comp = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('zipcode', make_pipeline(zipcode_transformer, SimpleImputer(strategy='median')), zipcode_col),\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('date', make_pipeline(date_transformer, SimpleImputer(strategy='median')), date_cols),\n",
    "        ('APE', make_pipeline(APE_transformer, SimpleImputer(strategy='median')), APE_col),\n",
    "        ('drop cols', 'drop', drop_cols),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure it works\n",
    "preprocessor_comp.fit_transform(X_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a Random Forest Regressor model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can test our model, we need to define our unique scoring function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def loss(y_true, y_pred):\n",
    "    \n",
    "    if isinstance(y_true, pd.Series):\n",
    "        y_true = y_true.values\n",
    "\n",
    "    true = np.maximum(5., np.log10(np.maximum(1., y_true)))\n",
    "    pred = np.maximum(5., np.log10(np.maximum(1., y_pred)))\n",
    "    \n",
    "    loss = np.mean(np.abs(true - pred))\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "fan_loss = make_scorer(loss, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test our model. Note that we use `GroupShuffleSplit` using `Legal_ID` as the group so that the same company ('Legal_ID') only appears in either 'train' or 'test' but does not appear both in 'train' **and** 'test'.\n",
    "\n",
    "This reflects the same conditions of this challenge where, the private 'test' data (on RAMP) does not contain any company that also appears in the public 'train' dataset you have access to. This is because `Revenue` for the same company is often very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor_comp),\n",
    "    ('classifier', regressor)])\n",
    "\n",
    "cv = GroupShuffleSplit(n_splits=8, test_size=0.25)\n",
    "\n",
    "scores_Xdf = -cross_val_score(clf, X_df, y_array, cv=cv, scoring=fan_loss, groups=X_df['Legal_ID'], n_jobs=2)\n",
    "\n",
    "print(\"mean: %e (+/- %e)\" % (scores_Xdf.mean(), scores_Xdf.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive merge\n",
    "\n",
    "Now let us predict using a naive merge of `award` and `comp` datasets.\n",
    "\n",
    "The naive merge will only use the name of the company. To aid the merging we will convert the name to all lower case and remove punctuation and white space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "award['Name_processed'] = award['incumbent_name'].str.lower()\n",
    "award['Name_processed'] = award['Name_processed'].str.replace('[^\\w]','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each company, extract 2 features:\n",
    "\n",
    "* the number of award lots won\n",
    "* the total sum of award lots won"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "award_features = award.groupby(['Name_processed'])['amount'].agg(['count','sum'])\n",
    "award_features.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will perform a naive merge of `X_df` and `award_features`. \n",
    "\n",
    "Be careful in this step to ensure that the **order** of `X_df` is not changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_naive(X):\n",
    "    X['Name'] = X['Name'].str.lower()     \n",
    "    X['Name'] = X['Name'].str.replace('[^\\w]','')\n",
    "    df = pd.merge(X, award_features, left_on='Name', right_on='Name_processed', how='left')\n",
    "    return df[['count','sum']]\n",
    "merge_transformer = FunctionTransformer(merge_naive, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the same feature transformation steps as above and include the 'merge' step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode_col = ['Zipcode']\n",
    "date_cols = ['Fiscal_year_end_date']\n",
    "drop_cols = ['Address', 'City']\n",
    "APE_col = ['Activity_code (APE)']\n",
    "merge_col = ['Name']\n",
    "\n",
    "preprocessor_merge = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('zipcode', make_pipeline(zipcode_transformer, SimpleImputer(strategy='median')), zipcode_col),\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('date', make_pipeline(date_transformer, SimpleImputer(strategy='median')), date_cols),\n",
    "        ('APE', make_pipeline(APE_transformer, SimpleImputer(strategy='median')), APE_col),\n",
    "        ('merge', make_pipeline(merge_transformer, SimpleImputer(strategy='median')), merge_col),\n",
    "        ('drop cols', 'drop', drop_cols),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check it works\n",
    "preprocessor_merge.fit_transform(X_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is implemented in RAMP within the files in the folder `submissions/starting_kit`. \n",
    "\n",
    "The transformation steps above are implemented in the file `submissions/starting_kit/feature_extractor.py` (a copy of this file is shown below). This file needs to define a class called `FeatureExtractor` which requires a `fit()` and `transform()` function. The `fit()` function takes both `X_df` and `y_array` as parameters, meaning that you are able to engineer new features using `y_array` (e.g. target encoding). The `transform()` function only takes `X_df`. We only use the `transform()` function in our simple example below.\n",
    "\n",
    "Note that the `award` dataset is being read in from the submission folder (`submissions/starting_kit`). This means that when testing locally, each submission folder should contain a copy of the award dataset `award_notices_RAMP.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "class FeatureExtractor(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y_array):\n",
    "        pass\n",
    "\n",
    "    def transform(self, X_df):\n",
    "        X_encoded = X_df\n",
    "\n",
    "        path = os.path.dirname(__file__)\n",
    "        award = pd.read_csv(os.path.join(path, 'award_notices_RAMP.csv.zip', compression='zip'),\n",
    "                            low_memory=False)\n",
    "        # obtain features from award\n",
    "        award['Name_processed'] = award['incumbent_name'].str.lower()\n",
    "        award['Name_processed'] = award['Name_processed'].str.replace('[^\\w]','')\n",
    "        award_features = award.groupby(['Name_processed'])['amount'].agg(['count','sum'])\n",
    "\n",
    "        def zipcodes(X):\n",
    "            zipcode_nums = pd.to_numeric(X['Zipcode'], errors='coerce')\n",
    "            return zipcode_nums.values[:, np.newaxis]\n",
    "        zipcode_transformer = FunctionTransformer(zipcodes, validate=False)\n",
    "\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "            ('impute', SimpleImputer(strategy='median'))])\n",
    "\n",
    "        def process_date(X):\n",
    "            date = pd.to_datetime(X['Fiscal_year_end_date'], format='%Y-%m-%d')\n",
    "            return np.c_[date.dt.year, date.dt.month, date.dt.day]\n",
    "        date_transformer = FunctionTransformer(process_date, validate=False)\n",
    "        \n",
    "        def process_APE(X):\n",
    "            APE = X['Activity_code (APE)'].str[:2]\n",
    "            return pd.to_numeric(APE).values[:, np.newaxis]\n",
    "        APE_transformer = FunctionTransformer(process_APE, validate=False)\n",
    "\n",
    "        def merge_naive(X):\n",
    "            X['Name'] = X['Name'].str.lower()     \n",
    "            X['Name'] = X['Name'].str.replace('[^\\w]','')\n",
    "            df = pd.merge(X, award_features, left_on='Name', \n",
    "                          right_on='Name_processed', how='left')\n",
    "            return df[['count','sum']]\n",
    "        merge_transformer = FunctionTransformer(merge_naive, validate=False)\n",
    "\n",
    "        num_cols = ['Legal_ID', 'Headcount', \n",
    "                    'Fiscal_year_duration_in_months', 'Year']\n",
    "        zipcode_col = ['Zipcode']\n",
    "        date_cols = ['Fiscal_year_end_date']\n",
    "        APE_col = ['Activity_code (APE)']\n",
    "        merge_col = ['Name']\n",
    "        drop_cols = ['Address', 'City']\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('zipcode', make_pipeline(zipcode_transformer, SimpleImputer(strategy='median')), zipcode_col),\n",
    "                ('num', numeric_transformer, num_cols),\n",
    "                ('date', make_pipeline(date_transformer, SimpleImputer(strategy='median')), date_cols),\n",
    "                ('APE', make_pipeline(APE_transformer, SimpleImputer(strategy='median')), APE_col),\n",
    "                ('merge', make_pipeline(merge_transformer, SimpleImputer(strategy='median')), merge_col),\n",
    "                ('drop cols', 'drop', drop_cols),\n",
    "                ])\n",
    "\n",
    "        X_array = preprocessor.fit_transform(X_encoded)\n",
    "        return X_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a Random Forest Regressor model again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is implemented in the file `submissions/starting_kit/regressor.py` (a copy of this file is shown below). The `Regressor` class must have a `fit()` and `predict()` function. If you are using a scikit-learn function, this can be done by simply calling `fit()` and `predict()` on the regressor, as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "class Regressor(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.reg = RandomForestRegressor(n_estimators=5)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.reg.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.reg.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test our model within this notebook, using `preprocessor_merge` and `regressor` defined above, in a `Pipeline()`. \n",
    "\n",
    "Once you are happy with a solution, you can transfer your solution to `feature_extractor.py` and `regressor.py` files and test your submission using RAMP (see 'Submissions')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor_merge),\n",
    "    ('classifier', regressor)])\n",
    "\n",
    "cv = GroupShuffleSplit(n_splits=8, test_size=0.25)\n",
    "\n",
    "scores_merge = -cross_val_score(clf, X_df, y_array, cv=cv, scoring=fan_loss, groups=X_df['Legal_ID'],\n",
    "                               n_jobs=2)\n",
    "\n",
    "print(\"mean: %e (+/- %e)\" % (scores_merge.mean(), scores_merge.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score comparison\n",
    "\n",
    "You can see in the below plot of the scores that using the merged data always results in better scores (smaller is better):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame({'Xdf': scores_Xdf, 'merge': scores_merge})\n",
    "scores.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record linkage\n",
    "\n",
    "The problem of trying to match 'records' referring to the same entity across different data sources is called  record linkage. We used a very naive way to match companies above but there are much more sophiisticated methods and packages implementing these methods. To get you started here are two Python packages:\n",
    "\n",
    "* [Python Record Linkage Toolkit](https://recordlinkage.readthedocs.io/en/latest/index.html)\n",
    "* [Dedupe](https://github.com/dedupeio/dedupe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission structure\n",
    "\n",
    "Each of your submissions should be in it's own folder within the `submissions` folder (e.g. `submissions/my_submission`). The submission directory should contain 3 files:\n",
    "\n",
    "* a copy of the `award_notices_RAMP.csv` dataset. Note that you will **not** need to upload this file when making a submission in RAMP studio as this is done automatically by RAMP studio.\n",
    "* `feature_extractor.py` - this should merge the `X_df` and the award dataset and any feature transformation you wish\n",
    "* `regressor.py` - this should implement a regressor with a `fit()` and `predict()` function\n",
    "\n",
    "See `submissions/starting_kit` for an example.\n",
    "\n",
    "You can also test your submissions using RAMP-workflow before submitting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local testing (before submission)\n",
    "\n",
    "It is <b><span style=\"color:red\">important that you test your submission files before submitting them</span></b>. For this we provide a unit test - `ramp_test_submission`. \n",
    "\n",
    "First, ensure that `ramp-worflow` is installed (see the [github repo](https://github.com/paris-saclay-cds/ramp-workflow) for installation instructions). \n",
    "\n",
    "Now you can use `ramp_test_submission`. This command will test on files in [`submissions/starting_kit`](/submissions/starting_kit) by default. To specify testing on a different folder use the flag `--submission`. For example to run the test on `submissions/solution1` use: `ramp_test_submission --submission solution1`.\n",
    "\n",
    "If it runs and print training and test errors on each fold, then you can submit the code.\n",
    "\n",
    "For example, below we test the starting kit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ramp_test_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting to [ramp.studio](http://ramp.studio)\n",
    "\n",
    "Once you found a good model, you can submit it to [ramp.studio](http://www.ramp.studio). First, if it is your first time using RAMP, [sign up](http://www.ramp.studio/sign_up), otherwise [log in](http://www.ramp.studio/login). Then sign up for the 'FAN_revenue_prediction' challenge and the 'Saclay M2 Data Camp 2019/20' [event](https://ramp.studio/events/fan_revenue_prediction_saclay_datacamp_19). Both signups are controlled by RAMP administrators, so there **can be a delay between asking for signup and being able to submit**.\n",
    "\n",
    "Once your signup request is accepted, you can go to your [sandbox](https://ramp.studio/events/fan_revenue_prediction_saclay_datacamp_19/sandbox). Here you can either edit and save the code files on the left hand side of the page or upload your `feature_extractor.py` and `regressor.py` files on the right hand side of the page, then give your submission a name and click 'submit'. The submission is trained and tested on our backend in the same way as `ramp_test_submission` does it locally. While your submission is waiting in the queue and being trained, you can find it in the \"New submissions (pending training)\" table in [my submissions](https://ramp.studio/events/fan_revenue_prediction_saclay_datacamp_19/my_submissions). Once it is trained, you get an email, and your submission shows up on the [public leaderboard](https://ramp.studio/events/fan_revenue_prediction_saclay_datacamp_19/leaderboard). \n",
    "If there is an error (despite having tested your submission locally with `ramp_test_submission`), it will show up in the \"Failed submissions\" table in [my submissions](https://ramp.studio/events/fan_revenue_prediction_saclay_datacamp_19/my_submissions). You can click on the error to see part of the trace.\n",
    "\n",
    "After submission, do not forget to give credits to the previous submissions you reused or integrated into your submission.\n",
    "\n",
    "The data set we use at the backend is usually different from what you find in the starting kit, so the score may be different.\n",
    "\n",
    "The usual way to work with RAMP is to explore solutions, add feature transformations, select models, perhaps do some AutoML/hyperopt, etc., _locally_ then check that your submission works locally with `ramp_test_submission`. The script will print mean cross-validation scores if your submission works.\n",
    "\n",
    "The official score in this RAMP (the first score column after \"historical contributivity\" on the [leaderboard](https://ramp.studio/events/fan_revenue_prediction_saclay_datacamp_19/leaderboard)) is `FAN error`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More information\n",
    "\n",
    "You can find more information in the [README](https://github.com/paris-saclay-cds/ramp-workflow/blob/master/README.md) of the [ramp-workflow library](https://github.com/paris-saclay-cds/ramp-workflow)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
